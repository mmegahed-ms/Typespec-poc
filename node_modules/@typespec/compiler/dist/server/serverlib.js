import { Diagnostic as VSDiagnostic, DiagnosticSeverity, DiagnosticTag, DocumentHighlightKind, MarkupKind, Range, SemanticTokensBuilder, TextDocumentSyncKind, TextEdit, } from "vscode-languageserver/node.js";
import { defaultConfig, findTypeSpecConfigPath, loadTypeSpecConfigFile, } from "../config/config-loader.js";
import { codePointBefore, isIdentifierContinue } from "../core/charcode.js";
import { compilerAssert, createSourceFile, formatDiagnostic, getSourceLocation, } from "../core/diagnostics.js";
import { formatTypeSpec } from "../core/formatter.js";
import { getTypeName } from "../core/helpers/type-name-utils.js";
import { getNodeAtPosition, visitChildren } from "../core/parser.js";
import { ensureTrailingDirectorySeparator, getDirectoryPath, joinPaths, } from "../core/path-utils.js";
import { compile as compileProgram } from "../core/program.js";
import { createScanner, isKeyword, isPunctuation, skipTrivia, skipWhiteSpace, Token, } from "../core/scanner.js";
import { SyntaxKind, } from "../core/types.js";
import { doIO, getNormalizedRealPath, getSourceFileKindFromExt, loadFile, resolveTspMain, } from "../core/util.js";
import { resolveCompletion } from "./completion.js";
import { getSymbolStructure } from "./symbol-structure.js";
import { getParameterDocumentation, getTypeDetails } from "./type-details.js";
export var SemanticTokenKind;
(function (SemanticTokenKind) {
    SemanticTokenKind[SemanticTokenKind["Namespace"] = 0] = "Namespace";
    SemanticTokenKind[SemanticTokenKind["Type"] = 1] = "Type";
    SemanticTokenKind[SemanticTokenKind["Class"] = 2] = "Class";
    SemanticTokenKind[SemanticTokenKind["Enum"] = 3] = "Enum";
    SemanticTokenKind[SemanticTokenKind["Interface"] = 4] = "Interface";
    SemanticTokenKind[SemanticTokenKind["Struct"] = 5] = "Struct";
    SemanticTokenKind[SemanticTokenKind["TypeParameter"] = 6] = "TypeParameter";
    SemanticTokenKind[SemanticTokenKind["Parameter"] = 7] = "Parameter";
    SemanticTokenKind[SemanticTokenKind["Variable"] = 8] = "Variable";
    SemanticTokenKind[SemanticTokenKind["Property"] = 9] = "Property";
    SemanticTokenKind[SemanticTokenKind["EnumMember"] = 10] = "EnumMember";
    SemanticTokenKind[SemanticTokenKind["Event"] = 11] = "Event";
    SemanticTokenKind[SemanticTokenKind["Function"] = 12] = "Function";
    SemanticTokenKind[SemanticTokenKind["Method"] = 13] = "Method";
    SemanticTokenKind[SemanticTokenKind["Macro"] = 14] = "Macro";
    SemanticTokenKind[SemanticTokenKind["Keyword"] = 15] = "Keyword";
    SemanticTokenKind[SemanticTokenKind["Comment"] = 16] = "Comment";
    SemanticTokenKind[SemanticTokenKind["String"] = 17] = "String";
    SemanticTokenKind[SemanticTokenKind["Number"] = 18] = "Number";
    SemanticTokenKind[SemanticTokenKind["Regexp"] = 19] = "Regexp";
    SemanticTokenKind[SemanticTokenKind["Operator"] = 20] = "Operator";
})(SemanticTokenKind = SemanticTokenKind || (SemanticTokenKind = {}));
const serverOptions = {
    noEmit: true,
    designTimeBuild: true,
    parseOptions: {
        comments: true,
        docs: true,
    },
};
export function createServer(host) {
    // Remember original URL when we convert it to a local path so that we can
    // get it back. We can't convert it back because things like URL-encoding
    // could give us back an equivalent but non-identical URL but the original
    // URL is used as a key into the opened documents and so we must reproduce
    // it exactly.
    const pathToURLMap = new Map();
    // Cache all file I/O. Only open documents are sent over the LSP pipe. When
    // the compiler reads a file that isn't open, we use this cache to avoid
    // hitting the disk. Entries are invalidated when LSP client notifies us of
    // a file change.
    const fileSystemCache = createFileSystemCache();
    const compilerHost = createCompilerHost();
    const oldPrograms = new Map();
    let workspaceFolders = [];
    let isInitialized = false;
    let pendingMessages = [];
    return {
        get pendingMessages() {
            return pendingMessages;
        },
        get workspaceFolders() {
            return workspaceFolders;
        },
        compile,
        initialize,
        initialized,
        workspaceFoldersChanged,
        watchedFilesChanged,
        formatDocument,
        gotoDefinition,
        documentClosed,
        complete,
        findReferences,
        findDocumentHighlight,
        prepareRename,
        rename,
        getSemanticTokens,
        buildSemanticTokens,
        checkChange,
        getFoldingRanges,
        getHover,
        getSignatureHelp,
        getDocumentSymbols,
        log,
    };
    async function initialize(params) {
        var _a, _b;
        const tokenLegend = {
            tokenTypes: Object.keys(SemanticTokenKind)
                .filter((x) => Number.isNaN(Number(x)))
                .map((x) => x.slice(0, 1).toLocaleLowerCase() + x.slice(1)),
            tokenModifiers: [],
        };
        const capabilities = {
            textDocumentSync: TextDocumentSyncKind.Incremental,
            definitionProvider: true,
            foldingRangeProvider: true,
            hoverProvider: true,
            documentSymbolProvider: true,
            documentHighlightProvider: true,
            completionProvider: {
                resolveProvider: false,
                triggerCharacters: [".", "@", "/"],
            },
            semanticTokensProvider: {
                full: true,
                legend: tokenLegend,
            },
            referencesProvider: true,
            renameProvider: {
                prepareProvider: true,
            },
            documentFormattingProvider: true,
            signatureHelpProvider: {
                triggerCharacters: ["(", ",", "<"],
                retriggerCharacters: [")"],
            },
        };
        if ((_a = params.capabilities.workspace) === null || _a === void 0 ? void 0 : _a.workspaceFolders) {
            for (const w of (_b = params.workspaceFolders) !== null && _b !== void 0 ? _b : []) {
                workspaceFolders.push({
                    ...w,
                    path: ensureTrailingDirectorySeparator(await fileURLToRealPath(w.uri)),
                });
            }
            capabilities.workspace = {
                workspaceFolders: {
                    supported: true,
                    changeNotifications: true,
                },
            };
        }
        else if (params.rootUri) {
            workspaceFolders = [
                {
                    name: "<root>",
                    uri: params.rootUri,
                    path: ensureTrailingDirectorySeparator(await fileURLToRealPath(params.rootUri)),
                },
            ];
        }
        else if (params.rootPath) {
            workspaceFolders = [
                {
                    name: "<root>",
                    uri: compilerHost.pathToFileURL(params.rootPath),
                    path: ensureTrailingDirectorySeparator(await getNormalizedRealPath(compilerHost, params.rootPath)),
                },
            ];
        }
        log("Workspace Folders", workspaceFolders);
        return { capabilities };
    }
    function initialized(params) {
        isInitialized = true;
        log("Initialization complete.");
    }
    async function workspaceFoldersChanged(e) {
        log("Workspace Folders Changed", e);
        const map = new Map(workspaceFolders.map((f) => [f.uri, f]));
        for (const folder of e.removed) {
            map.delete(folder.uri);
        }
        for (const folder of e.added) {
            map.set(folder.uri, {
                ...folder,
                path: ensureTrailingDirectorySeparator(await fileURLToRealPath(folder.uri)),
            });
        }
        workspaceFolders = Array.from(map.values());
        log("Workspace Folders", workspaceFolders);
    }
    function watchedFilesChanged(params) {
        fileSystemCache.notify(params.changes);
    }
    async function compile(document, callback) {
        const path = await getPath(document);
        const mainFile = await getMainFileForDocument(path);
        const config = await getConfig(mainFile, path);
        const options = {
            ...serverOptions,
            emit: config.emit,
            options: config.options,
        };
        if (!upToDate(document)) {
            return undefined;
        }
        let program;
        try {
            program = await compileProgram(compilerHost, mainFile, options, oldPrograms.get(mainFile));
            oldPrograms.set(mainFile, program);
            if (!upToDate(document)) {
                return undefined;
            }
            if (mainFile !== path && !program.sourceFiles.has(path)) {
                // If the file that changed wasn't imported by anything from the main
                // file, retry using the file itself as the main file.
                program = await compileProgram(compilerHost, path, options, oldPrograms.get(path));
                oldPrograms.set(path, program);
            }
            if (!upToDate(document)) {
                return undefined;
            }
            if (callback) {
                const doc = "version" in document ? document : host.getOpenDocumentByURL(document.uri);
                compilerAssert(doc, "Failed to get document.");
                const path = await getPath(doc);
                const script = program.sourceFiles.get(path);
                compilerAssert(script, "Failed to get script.");
                return await callback(program, doc, script);
            }
            return program;
        }
        catch (err) {
            if (host.throwInternalErrors) {
                throw err;
            }
            host.sendDiagnostics({
                uri: document.uri,
                diagnostics: [
                    {
                        severity: DiagnosticSeverity.Error,
                        range: Range.create(0, 0, 0, 0),
                        message: `Internal compiler error!\nFile issue at https://github.com/microsoft/typespec\n\n` +
                            err.stack,
                    },
                ],
            });
            return undefined;
        }
    }
    async function getConfig(mainFile, path) {
        const configPath = await findTypeSpecConfigPath(compilerHost, mainFile);
        if (!configPath) {
            return { ...defaultConfig, projectRoot: getDirectoryPath(mainFile) };
        }
        const cached = await fileSystemCache.get(configPath);
        if (cached === null || cached === void 0 ? void 0 : cached.data) {
            return cached.data;
        }
        const config = await loadTypeSpecConfigFile(compilerHost, configPath);
        await fileSystemCache.setData(configPath, config);
        return config;
    }
    async function getScript(document) {
        var _a;
        const file = await compilerHost.readFile(await getPath(document));
        const cached = (_a = compilerHost.parseCache) === null || _a === void 0 ? void 0 : _a.get(file);
        return cached !== null && cached !== void 0 ? cached : (await compile(document, (_, __, script) => script));
    }
    async function getFoldingRanges(params) {
        const ast = await getScript(params.textDocument);
        if (!ast) {
            return [];
        }
        const file = ast.file;
        const ranges = [];
        let rangeStartSingleLines = -1;
        for (let i = 0; i < ast.comments.length; i++) {
            const comment = ast.comments[i];
            if (comment.kind === SyntaxKind.LineComment &&
                i + 1 < ast.comments.length &&
                ast.comments[i + 1].kind === SyntaxKind.LineComment &&
                ast.comments[i + 1].pos === skipWhiteSpace(file.text, comment.end)) {
                if (rangeStartSingleLines === -1) {
                    rangeStartSingleLines = comment.pos;
                }
            }
            else if (rangeStartSingleLines !== -1) {
                addRange(rangeStartSingleLines, comment.end);
                rangeStartSingleLines = -1;
            }
            else {
                addRange(comment.pos, comment.end);
            }
        }
        visitChildren(ast, addRangesForNode);
        function addRangesForNode(node) {
            if (node.kind === SyntaxKind.Doc) {
                return; // fold doc comments as regular comments
            }
            let nodeStart = node.pos;
            if ("decorators" in node && node.decorators.length > 0) {
                const decoratorEnd = node.decorators[node.decorators.length - 1].end;
                addRange(nodeStart, decoratorEnd);
                nodeStart = skipTrivia(file.text, decoratorEnd);
            }
            addRange(nodeStart, node.end);
            visitChildren(node, addRangesForNode);
        }
        return ranges;
        function addRange(startPos, endPos) {
            const start = file.getLineAndCharacterOfPosition(startPos);
            const end = file.getLineAndCharacterOfPosition(endPos);
            if (start.line !== end.line) {
                ranges.push({
                    startLine: start.line,
                    startCharacter: start.character,
                    endLine: end.line,
                    endCharacter: end.character,
                });
            }
        }
    }
    async function getDocumentSymbols(params) {
        const ast = await getScript(params.textDocument);
        if (!ast) {
            return [];
        }
        return getSymbolStructure(ast);
    }
    async function findDocumentHighlight(params) {
        let highlights = [];
        await compile(params.textDocument, (program, document, file) => {
            const identifiers = findReferenceIdentifiers(program, file, document.offsetAt(params.position), [file]);
            highlights = identifiers.map((identifier) => ({
                range: getRange(identifier, file.file),
                kind: DocumentHighlightKind.Read,
            }));
        });
        return highlights;
    }
    async function checkChange(change) {
        var _a, _b, _c;
        const program = await compile(change.document);
        if (!program) {
            return;
        }
        // Group diagnostics by file.
        //
        // Initialize diagnostics for all source files in program to empty array
        // as we must send an empty array when a file has no diagnostics or else
        // stale diagnostics from a previous run will stick around in the IDE.
        //
        const diagnosticMap = new Map();
        diagnosticMap.set(change.document, []);
        for (const each of program.sourceFiles.values()) {
            const document = (_a = each.file) === null || _a === void 0 ? void 0 : _a.document;
            if (document) {
                diagnosticMap.set(document, []);
            }
        }
        for (const each of program.diagnostics) {
            let document;
            const location = getSourceLocation(each.target);
            if (location === null || location === void 0 ? void 0 : location.file) {
                document = location.file.document;
            }
            else {
                // https://github.com/Microsoft/language-server-protocol/issues/256
                //
                // LSP does not currently allow sending a diagnostic with no location so
                // we report diagnostics with no location on the document that changed to
                // trigger.
                document = change.document;
            }
            if (!document || !upToDate(document)) {
                continue;
            }
            const start = document.positionAt((_b = location === null || location === void 0 ? void 0 : location.pos) !== null && _b !== void 0 ? _b : 0);
            const end = document.positionAt((_c = location === null || location === void 0 ? void 0 : location.end) !== null && _c !== void 0 ? _c : 0);
            const range = Range.create(start, end);
            const severity = convertSeverity(each.severity);
            const diagnostic = VSDiagnostic.create(range, each.message, severity, each.code, "TypeSpec");
            if (each.code === "deprecated") {
                diagnostic.tags = [DiagnosticTag.Deprecated];
            }
            const diagnostics = diagnosticMap.get(document);
            compilerAssert(diagnostics, "Diagnostic reported against a source file that was not added to the program.");
            diagnostics.push(diagnostic);
        }
        for (const [document, diagnostics] of diagnosticMap) {
            sendDiagnostics(document, diagnostics);
        }
    }
    async function getHover(params) {
        const docString = await compile(params.textDocument, (program, document, file) => {
            var _a;
            const id = getNodeAtPosition(file, document.offsetAt(params.position));
            const sym = (id === null || id === void 0 ? void 0 : id.kind) === SyntaxKind.Identifier ? program.checker.resolveIdentifier(id) : undefined;
            if (sym) {
                const type = (_a = sym.type) !== null && _a !== void 0 ? _a : program.checker.getTypeForNode(sym.declarations[0]);
                return getTypeDetails(program, type);
            }
            return undefined;
        });
        const markdown = {
            kind: MarkupKind.Markdown,
            value: docString !== null && docString !== void 0 ? docString : "",
        };
        return {
            contents: markdown,
        };
    }
    async function getSignatureHelp(params) {
        return await compile(params.textDocument, (program, document, file) => {
            const nodeAtPosition = getNodeAtPosition(file, document.offsetAt(params.position));
            const data = nodeAtPosition && findDecoratorOrParameter(nodeAtPosition);
            if (data === undefined) {
                return undefined;
            }
            const { node, argumentIndex } = data;
            const sym = program.checker.resolveIdentifier(node.target.kind === SyntaxKind.MemberExpression ? node.target.id : node.target);
            const decoratorDeclNode = sym === null || sym === void 0 ? void 0 : sym.declarations.find((x) => x.kind === SyntaxKind.DecoratorDeclarationStatement);
            if (decoratorDeclNode === undefined) {
                return undefined;
            }
            const type = program.checker.getTypeForNode(decoratorDeclNode);
            compilerAssert(type.kind === "Decorator", "Expected type to be a decorator.");
            const parameterDocs = getParameterDocumentation(program, type);
            let labelPrefix = "";
            const parameters = [];
            if (node.kind === SyntaxKind.AugmentDecoratorStatement) {
                const targetType = decoratorDeclNode.target.type
                    ? program.checker.getTypeForNode(decoratorDeclNode.target.type)
                    : undefined;
                parameters.push({
                    label: `${decoratorDeclNode.target.id.sv}: ${targetType ? getTypeName(targetType) : "unknown"}`,
                });
                labelPrefix = "@";
            }
            parameters.push(...type.parameters.map((x) => {
                const info = {
                    // prettier-ignore
                    label: `${x.rest ? "..." : ""}${x.name}${x.optional ? "?" : ""}: ${getTypeName(x.type)}`,
                };
                const doc = parameterDocs.get(x.name);
                if (doc) {
                    info.documentation = { kind: MarkupKind.Markdown, value: doc };
                }
                return info;
            }));
            const help = {
                signatures: [
                    {
                        label: `${labelPrefix}${type.name}(${parameters.map((x) => x.label).join(", ")})`,
                        parameters,
                        activeParameter: Math.min(parameters.length - 1, argumentIndex),
                    },
                ],
                activeSignature: 0,
                activeParameter: 0,
            };
            const doc = getTypeDetails(program, type, {
                includeSignature: false,
                includeParameterTags: false,
            });
            if (doc) {
                help.signatures[0].documentation = { kind: MarkupKind.Markdown, value: doc };
            }
            return help;
        });
    }
    async function formatDocument(params) {
        const document = host.getOpenDocumentByURL(params.textDocument.uri);
        if (document === undefined) {
            return [];
        }
        const formattedText = formatTypeSpec(document.getText(), {
            tabWidth: params.options.tabSize,
            useTabs: !params.options.insertSpaces,
        });
        return [minimalEdit(document, formattedText)];
    }
    function minimalEdit(document, string1) {
        const string0 = document.getText();
        // length of common prefix
        let i = 0;
        while (i < string0.length && i < string1.length && string0[i] === string1[i]) {
            ++i;
        }
        // length of common suffix
        let j = 0;
        while (i + j < string0.length &&
            i + j < string1.length &&
            string0[string0.length - j - 1] === string1[string1.length - j - 1]) {
            ++j;
        }
        const newText = string1.substring(i, string1.length - j);
        const pos0 = document.positionAt(i);
        const pos1 = document.positionAt(string0.length - j);
        return TextEdit.replace(Range.create(pos0, pos1), newText);
    }
    async function gotoDefinition(params) {
        const sym = await compile(params.textDocument, (program, document, file) => {
            const id = getNodeAtPosition(file, document.offsetAt(params.position));
            return (id === null || id === void 0 ? void 0 : id.kind) === SyntaxKind.Identifier ? program.checker.resolveIdentifier(id) : undefined;
        });
        return getLocations(sym === null || sym === void 0 ? void 0 : sym.declarations);
    }
    async function complete(params) {
        const completions = {
            isIncomplete: false,
            items: [],
        };
        await compile(params.textDocument, async (program, document, file) => {
            const node = getCompletionNodeAtPosition(file, document.offsetAt(params.position));
            await resolveCompletion({
                program,
                file,
                completions,
                params,
            }, node);
        });
        return completions;
    }
    async function findReferences(params) {
        const identifiers = await compile(params.textDocument, (program, document, file) => findReferenceIdentifiers(program, file, document.offsetAt(params.position)));
        return getLocations(identifiers);
    }
    async function prepareRename(params) {
        return await compile(params.textDocument, (_, document, file) => {
            var _a;
            const id = getNodeAtPosition(file, document.offsetAt(params.position));
            return (id === null || id === void 0 ? void 0 : id.kind) === SyntaxKind.Identifier ? (_a = getLocation(id)) === null || _a === void 0 ? void 0 : _a.range : undefined;
        });
    }
    async function rename(params) {
        const changes = {};
        await compile(params.textDocument, (program, document, file) => {
            const identifiers = findReferenceIdentifiers(program, file, document.offsetAt(params.position));
            for (const id of identifiers) {
                const location = getLocation(id);
                if (!location) {
                    continue;
                }
                const change = TextEdit.replace(location.range, params.newName);
                if (location.uri in changes) {
                    changes[location.uri].push(change);
                }
                else {
                    changes[location.uri] = [change];
                }
            }
        });
        return { changes };
    }
    function findReferenceIdentifiers(program, file, pos, searchFiles = program.sourceFiles.values()) {
        const id = getNodeAtPosition(file, pos);
        if ((id === null || id === void 0 ? void 0 : id.kind) !== SyntaxKind.Identifier) {
            return [];
        }
        const sym = program.checker.resolveIdentifier(id);
        if (!sym) {
            return [id];
        }
        const references = [];
        for (const searchFile of searchFiles) {
            visitChildren(searchFile, function visit(node) {
                if (node.kind === SyntaxKind.Identifier) {
                    const s = program.checker.resolveIdentifier(node);
                    if (s === sym || (sym.type && (s === null || s === void 0 ? void 0 : s.type) === sym.type)) {
                        references.push(node);
                    }
                }
                visitChildren(node, visit);
            });
        }
        return references;
    }
    async function getSemanticTokens(params) {
        const ignore = -1;
        const defer = -2;
        const ast = await getScript(params.textDocument);
        if (!ast) {
            return [];
        }
        const file = ast.file;
        const tokens = mapTokens();
        classifyNode(ast);
        return Array.from(tokens.values()).filter((t) => t.kind !== undefined);
        function mapTokens() {
            const tokens = new Map();
            const scanner = createScanner(file, () => { });
            while (scanner.scan() !== Token.EndOfFile) {
                const kind = classifyToken(scanner.token);
                if (kind === ignore) {
                    continue;
                }
                tokens.set(scanner.tokenPosition, {
                    kind: kind === defer ? undefined : kind,
                    pos: scanner.tokenPosition,
                    end: scanner.position,
                });
            }
            return tokens;
        }
        function classifyToken(token) {
            switch (token) {
                case Token.Identifier:
                    return defer;
                case Token.StringLiteral:
                    return SemanticTokenKind.String;
                case Token.NumericLiteral:
                    return SemanticTokenKind.Number;
                case Token.MultiLineComment:
                case Token.SingleLineComment:
                    return SemanticTokenKind.Comment;
                default:
                    if (isKeyword(token)) {
                        return SemanticTokenKind.Keyword;
                    }
                    if (isPunctuation(token)) {
                        return SemanticTokenKind.Operator;
                    }
                    return ignore;
            }
        }
        function classifyNode(node) {
            switch (node.kind) {
                case SyntaxKind.DirectiveExpression:
                    classify(node.target, SemanticTokenKind.Keyword);
                    break;
                case SyntaxKind.TemplateParameterDeclaration:
                    classify(node.id, SemanticTokenKind.TypeParameter);
                    break;
                case SyntaxKind.ModelProperty:
                case SyntaxKind.UnionVariant:
                    classify(node.id, SemanticTokenKind.Property);
                    break;
                case SyntaxKind.AliasStatement:
                    classify(node.id, SemanticTokenKind.Struct);
                    break;
                case SyntaxKind.ModelStatement:
                    classify(node.id, SemanticTokenKind.Struct);
                    break;
                case SyntaxKind.ScalarStatement:
                    classify(node.id, SemanticTokenKind.Type);
                    break;
                case SyntaxKind.EnumStatement:
                    classify(node.id, SemanticTokenKind.Enum);
                    break;
                case SyntaxKind.EnumMember:
                    classify(node.id, SemanticTokenKind.EnumMember);
                    break;
                case SyntaxKind.NamespaceStatement:
                    classify(node.id, SemanticTokenKind.Namespace);
                    break;
                case SyntaxKind.InterfaceStatement:
                    classify(node.id, SemanticTokenKind.Interface);
                    break;
                case SyntaxKind.OperationStatement:
                    classify(node.id, SemanticTokenKind.Function);
                    break;
                case SyntaxKind.DecoratorDeclarationStatement:
                    classify(node.id, SemanticTokenKind.Function);
                    break;
                case SyntaxKind.FunctionDeclarationStatement:
                    classify(node.id, SemanticTokenKind.Function);
                    break;
                case SyntaxKind.FunctionParameter:
                    classify(node.id, SemanticTokenKind.Parameter);
                    break;
                case SyntaxKind.AugmentDecoratorStatement:
                    classifyReference(node.targetType, SemanticTokenKind.Type);
                    classifyReference(node.target, SemanticTokenKind.Macro);
                    break;
                case SyntaxKind.DecoratorExpression:
                    classifyReference(node.target, SemanticTokenKind.Macro);
                    break;
                case SyntaxKind.TypeReference:
                    classifyReference(node.target);
                    break;
                case SyntaxKind.MemberExpression:
                    classifyReference(node);
                    break;
                case SyntaxKind.ProjectionStatement:
                    classifyReference(node.selector);
                    classify(node.id, SemanticTokenKind.Variable);
                    break;
                case SyntaxKind.Projection:
                    classify(node.directionId, SemanticTokenKind.Keyword);
                    for (const modifierId of node.modifierIds) {
                        classify(modifierId, SemanticTokenKind.Keyword);
                    }
                    break;
                case SyntaxKind.ProjectionParameterDeclaration:
                    classifyReference(node.id, SemanticTokenKind.Parameter);
                    break;
                case SyntaxKind.ProjectionCallExpression:
                    classifyReference(node.target, SemanticTokenKind.Function);
                    for (const arg of node.arguments) {
                        classifyReference(arg);
                    }
                    break;
                case SyntaxKind.ProjectionMemberExpression:
                    classifyReference(node.id);
                    break;
            }
            visitChildren(node, classifyNode);
        }
        function classify(node, kind) {
            const token = tokens.get(node.pos);
            if (token && token.kind === undefined) {
                token.kind = kind;
            }
        }
        function classifyReference(node, kind = SemanticTokenKind.Type) {
            switch (node.kind) {
                case SyntaxKind.MemberExpression:
                    classifyIdentifier(node.base, SemanticTokenKind.Namespace);
                    classifyIdentifier(node.id, kind);
                    break;
                case SyntaxKind.ProjectionMemberExpression:
                    classifyReference(node.base, SemanticTokenKind.Namespace);
                    classifyIdentifier(node.id, kind);
                    break;
                case SyntaxKind.TypeReference:
                    classifyIdentifier(node.target, kind);
                    break;
                case SyntaxKind.Identifier:
                    classify(node, kind);
                    break;
            }
        }
        function classifyIdentifier(node, kind) {
            if (node.kind === SyntaxKind.Identifier) {
                classify(node, kind);
            }
        }
    }
    async function buildSemanticTokens(params) {
        const builder = new SemanticTokensBuilder();
        const tokens = await getSemanticTokens(params);
        const file = await compilerHost.readFile(await getPath(params.textDocument));
        const starts = file.getLineStarts();
        for (const token of tokens) {
            const start = file.getLineAndCharacterOfPosition(token.pos);
            const end = file.getLineAndCharacterOfPosition(token.end);
            for (let pos = token.pos, line = start.line; line <= end.line; line++) {
                const endPos = line === end.line ? token.end : starts[line + 1];
                const character = line === start.line ? start.character : 0;
                builder.push(line, character, endPos - pos, token.kind, 0);
                pos = endPos;
            }
        }
        return builder.build();
    }
    function documentClosed(change) {
        // clear diagnostics on file close
        sendDiagnostics(change.document, []);
    }
    function getLocations(targets) {
        var _a;
        return (_a = targets === null || targets === void 0 ? void 0 : targets.map(getLocation).filter((x) => !!x)) !== null && _a !== void 0 ? _a : [];
    }
    function getLocation(target) {
        const location = getSourceLocation(target);
        if (location.isSynthetic) {
            return undefined;
        }
        return {
            uri: getURL(location.file.path),
            range: getRange(location, location.file),
        };
    }
    function getRange(location, file) {
        const start = file.getLineAndCharacterOfPosition(location.pos);
        const end = file.getLineAndCharacterOfPosition(location.end);
        return Range.create(start, end);
    }
    function convertSeverity(severity) {
        switch (severity) {
            case "warning":
                return DiagnosticSeverity.Warning;
            case "error":
                return DiagnosticSeverity.Error;
        }
    }
    function log(message, details = undefined) {
        message = `[${new Date().toLocaleTimeString()}] ${message}`;
        if (details) {
            message += ": " + JSON.stringify(details, undefined, 2);
        }
        if (!isInitialized) {
            pendingMessages.push(message);
            return;
        }
        for (const pending of pendingMessages) {
            host.log(pending);
        }
        pendingMessages = [];
        host.log(message);
    }
    function sendDiagnostics(document, diagnostics) {
        host.sendDiagnostics({
            uri: document.uri,
            version: document.version,
            diagnostics,
        });
    }
    /**
     * Determine if the given document is the latest version.
     *
     * A document can become out-of-date if a change comes in during an async
     * operation.
     */
    function upToDate(document) {
        var _a;
        if (!("version" in document)) {
            return true;
        }
        return document.version === ((_a = host.getOpenDocumentByURL(document.uri)) === null || _a === void 0 ? void 0 : _a.version);
    }
    /**
     * Infer the appropriate entry point (a.k.a. "main file") for analyzing a
     * change to the file at the given path. This is necessary because different
     * results can be obtained from compiling the same file with different entry
     * points.
     *
     * Walk directory structure upwards looking for package.json with tspMain or
     * main.tsp file. Stop search when reaching a workspace root. If a root is
     * reached without finding an entry point, use the given path as its own
     * entry point.
     *
     * Untitled documents are always treated as their own entry points as they
     * do not exist in a directory that could pull them in via another entry
     * point.
     */
    async function getMainFileForDocument(path) {
        if (path.startsWith("untitled:")) {
            return path;
        }
        let dir = getDirectoryPath(path);
        const options = { allowFileNotFound: true };
        while (inWorkspace(dir)) {
            let mainFile = "main.tsp";
            let pkg;
            const pkgPath = joinPaths(dir, "package.json");
            const cached = await fileSystemCache.get(pkgPath);
            if (cached) {
                pkg = cached.data;
            }
            else {
                [pkg] = await loadFile(compilerHost, pkgPath, JSON.parse, logMainFileSearchDiagnostic, options);
                await fileSystemCache.setData(pkgPath, pkg !== null && pkg !== void 0 ? pkg : {});
            }
            const tspMain = resolveTspMain(pkg);
            if (typeof tspMain === "string") {
                mainFile = tspMain;
            }
            const candidate = joinPaths(dir, mainFile);
            const stat = await doIO(() => compilerHost.stat(candidate), candidate, logMainFileSearchDiagnostic, options);
            if (stat === null || stat === void 0 ? void 0 : stat.isFile()) {
                return candidate;
            }
            const parentDir = getDirectoryPath(dir);
            if (parentDir === dir) {
                break;
            }
            dir = parentDir;
        }
        return path;
        function logMainFileSearchDiagnostic(diagnostic) {
            log(`Unexpected diagnostic while looking for main file of ${path}`, formatDiagnostic(diagnostic));
        }
    }
    function inWorkspace(path) {
        path = ensureTrailingDirectorySeparator(path);
        return workspaceFolders.some((f) => path.startsWith(f.path));
    }
    async function getPath(document) {
        if (isUntitled(document.uri)) {
            return document.uri;
        }
        const path = await fileURLToRealPath(document.uri);
        pathToURLMap.set(path, document.uri);
        return path;
    }
    function getURL(path) {
        var _a;
        if (isUntitled(path)) {
            return path;
        }
        return (_a = pathToURLMap.get(path)) !== null && _a !== void 0 ? _a : compilerHost.pathToFileURL(path);
    }
    function isUntitled(pathOrUrl) {
        return pathOrUrl.startsWith("untitled:");
    }
    function getOpenDocument(path) {
        const url = getURL(path);
        return url ? host.getOpenDocumentByURL(url) : undefined;
    }
    async function fileURLToRealPath(url) {
        return getNormalizedRealPath(compilerHost, compilerHost.fileURLToPath(url));
    }
    function createFileSystemCache() {
        const cache = new Map();
        let changes = [];
        return {
            async get(path) {
                for (const change of changes) {
                    const path = await fileURLToRealPath(change.uri);
                    cache.delete(path);
                }
                changes = [];
                return cache.get(path);
            },
            set(path, entry) {
                cache.set(path, entry);
            },
            async setData(path, data) {
                const entry = await this.get(path);
                if (entry) {
                    entry.data = data;
                }
            },
            notify(changes) {
                changes.push(...changes);
            },
        };
    }
    function createCompilerHost() {
        const base = host.compilerHost;
        return {
            ...base,
            parseCache: new WeakMap(),
            readFile,
            stat,
            getSourceFileKind,
        };
        async function readFile(path) {
            const document = getOpenDocument(path);
            const cached = await fileSystemCache.get(path);
            // Try cache
            if (cached && (!document || document.version === cached.version)) {
                if (cached.type === "error") {
                    throw cached.error;
                }
                return cached.file;
            }
            // Try open document, although this is cheap, the instance still needs
            // to be cached so that the compiler can reuse parse and bind results.
            if (document) {
                const file = {
                    document,
                    ...createSourceFile(document.getText(), path),
                };
                fileSystemCache.set(path, { type: "file", file, version: document.version });
                return file;
            }
            // Hit the disk and cache
            try {
                const file = await base.readFile(path);
                fileSystemCache.set(path, { type: "file", file });
                return file;
            }
            catch (error) {
                fileSystemCache.set(path, { type: "error", error });
                throw error;
            }
        }
        async function stat(path) {
            var _a;
            // if we have an open document for the path or a cache entry, then we know
            // it's a file and not a directory and needn't hit the disk.
            if (getOpenDocument(path) || ((_a = (await fileSystemCache.get(path))) === null || _a === void 0 ? void 0 : _a.type) === "file") {
                return {
                    isFile() {
                        return true;
                    },
                    isDirectory() {
                        return false;
                    },
                };
            }
            return await base.stat(path);
        }
        function getSourceFileKind(path) {
            const document = getOpenDocument(path);
            if ((document === null || document === void 0 ? void 0 : document.languageId) === "typespec") {
                return "typespec";
            }
            return getSourceFileKindFromExt(path);
        }
    }
}
function findDecoratorOrParameter(node) {
    var _a, _b, _c;
    if (node.kind === SyntaxKind.DecoratorExpression) {
        return { node, argumentIndex: node.arguments.length };
    }
    if (node.kind === SyntaxKind.AugmentDecoratorStatement) {
        return { node, argumentIndex: node.arguments.length + 1 };
    }
    let current = node;
    while (current) {
        if (((_a = current.parent) === null || _a === void 0 ? void 0 : _a.kind) === SyntaxKind.DecoratorExpression) {
            return {
                node: current.parent,
                argumentIndex: current.parent.arguments.indexOf(current),
            };
        }
        if (((_b = current.parent) === null || _b === void 0 ? void 0 : _b.kind) === SyntaxKind.AugmentDecoratorStatement) {
            return {
                node: current.parent,
                argumentIndex: current === ((_c = current.parent) === null || _c === void 0 ? void 0 : _c.targetType)
                    ? 0
                    : current.parent.arguments.indexOf(current) + 1,
            };
        }
        current = current.parent;
    }
    return undefined;
}
/**
 * Resolve the node that should be auto completed at the given position.
 * It will try to guess what node it could be as during auto complete the ast might not be complete.
 * @internal
 */
export function getCompletionNodeAtPosition(script, position, filter = (node) => true) {
    const realNode = getNodeAtPosition(script, position, filter);
    if ((realNode === null || realNode === void 0 ? void 0 : realNode.kind) === SyntaxKind.StringLiteral) {
        return realNode;
    }
    // If we're not immediately after an identifier character, then advance
    // the position past any trivia. This is done because a zero-width
    // inserted missing identifier that the user is now trying to complete
    // starts after the trivia following the cursor.
    const cp = codePointBefore(script.file.text, position);
    if (!cp || !isIdentifierContinue(cp)) {
        const newPosition = skipTrivia(script.file.text, position);
        if (newPosition !== position) {
            return getNodeAtPosition(script, newPosition, filter);
        }
    }
    return realNode;
}
//# sourceMappingURL=serverlib.js.map